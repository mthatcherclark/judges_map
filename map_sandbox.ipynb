{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffcf01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "judges_url = 'https://www.fjc.gov/sites/default/files/history/federal-judicial-service.csv'\n",
    "\n",
    "judges_df_download = pd.read_csv(judges_url)\n",
    "\n",
    "# so we are going to be displaying polygons shaded by the percentage red or blue\n",
    "# there are different polygons for district and circuit and these can change over time\n",
    "# the districts changed each decade, affecting the circuit shape\n",
    "# further the circuit (5) became two (11 and 5) in 1981\n",
    "# We also want the user to be able to include or exclude senior judges\n",
    "# So, if we want to go back to the start of the court of appeals in 1911,\n",
    "# we will have ten sets of polygons for circuit (12-13) and district (94)\n",
    "# So, like 1,100 polygons in the GeoJSON file\n",
    "# AI suggests having one GEOJSON for the shapes and another for the data.\n",
    "# The data would have an entry for each of the roughly 46,000 days\n",
    "# Each day would have a district_id, circuit_id,\n",
    "# number of active judges for each party and number of active+senior judges for each party\n",
    "\n",
    "# Use this map for 2004 when Northern Mariana Islands was added to the 9th Circuit...\n",
    "# https://data.ojp.usdoj.gov/Shapefile/US-Attorney-Districts-Shapefile/5fdt-n5ne/about_data\n",
    "# We may need to let the data dictate when new districts, etc. were added\n",
    "\n",
    "\n",
    "# We may have to have a box that displays things like Supreme Court, territories, DC, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a412d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix nominating_party values that start with \"None\"\n",
    "# If there is no nominating party (usually because of a recess appointment that did not result in a commission),\n",
    "# use the last nominating party\n",
    "def fix_nominating_party(row):\n",
    "    if row['nominating_party'].startswith(\"None\"):\n",
    "        previous_rows = judges_df[(judges_df['nid'] == row['nid']) & (judges_df['start_date'] < row['start_date'])]\n",
    "        if not previous_rows.empty:\n",
    "            last_valid_row = previous_rows[~previous_rows['nominating_party'].str.startswith(\"None\")].sort_values('start_date', ascending=False).head(1)\n",
    "            if not last_valid_row.empty:\n",
    "                return last_valid_row['nominating_party'].values[0]\n",
    "    return row['nominating_party']\n",
    "\n",
    "# Preserve the original to avoid requesting the data again\n",
    "judges_df = judges_df_download.copy()\n",
    "\n",
    "# Fixing column headers by removing spaces, slashes and commas\n",
    "judges_df.columns = judges_df.columns.str.lower().str.replace(' ', '_').str.replace('/', '_').str.replace(',', '_')\n",
    "\n",
    "# The District Court of the District of Columbia was known by Supreme Court of the District of Columbia until 1936-ish\n",
    "# We will just call it the District Court of the District of Columbia throughout the data.\n",
    "judges_df['court_name'] = judges_df['court_name'].replace(r\"U.S. District Court for the District of Columbia (Supreme Court of the District of Columbia)\", \"U.S. District Court for the District of Columbia\")\n",
    "\n",
    "# start date is either recess appointment date or commission date\n",
    "judges_df['start_date'] = judges_df['recess_appointment_date'].fillna(judges_df['commission_date'])\n",
    "\n",
    "# Nominating party is the reappointing president, the appointing president if appointed on first try or George Washington if null.\n",
    "judges_df['nominating_party'] = judges_df['party_of_reappointing_president'].fillna(judges_df['party_of_appointing_president']).fillna(\"George Washington\")\n",
    "# Except some were recess appointments and had None as the nominating party because it was a recess appointment. We apply the party of the last appointment.\n",
    "judges_df['nominating_party'] = judges_df.apply(fix_nominating_party, axis=1)\n",
    "\n",
    "# Eliminate the courts that we do not want.\n",
    "# Courts of Appeals started in 1911. So, our start date will be Jan. 1, 1912.\n",
    "judges_df = judges_df[judges_df['court_type'].isin([\"Supreme Court\", \"U.S. District Court\", \"U.S. Court of Appeals\"])]\n",
    "\n",
    "# Make sure date columns are datetime\n",
    "judges_df['start_date'] = pd.to_datetime(judges_df['start_date'])\n",
    "judges_df['termination_date'] = pd.to_datetime(judges_df['termination_date'])\n",
    "judges_df['senior_status_date'] = pd.to_datetime(judges_df['senior_status_date'])\n",
    "\n",
    "# Define the cutoff date\n",
    "cutoff = pd.Timestamp('1912-01-01')\n",
    "\n",
    "# Filter to judges serving on the cutoff date or later\n",
    "judges_df = judges_df[\n",
    "    (((judges_df['start_date'] <= cutoff) & ((judges_df['termination_date'].isna()) | (judges_df['termination_date'] >= cutoff)))\n",
    "     | (judges_df['start_date'] > cutoff))\n",
    "]\n",
    "\n",
    "# Some helpful comparisons, at least for circuit courts:\n",
    "# https://www.acslaw.org/judicial-nominations/change-in-court-composition/\n",
    "# https://www.reddit.com/r/MapPorn/comments/18uxvdk/partisan_composition_of_every_district_courts/\n",
    "# https://en.wikipedia.org/wiki/Judicial_appointment_history_for_United_States_federal_courts#:~:text=As%20of%20January%202%2C%202025%2C%20of%20the%20679%20district%20court,a%20majority%20in%204%20circuits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1c1febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Parse dates\n",
    "df = judges_df.copy()\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df['termination_date'] = pd.to_datetime(df['termination_date'], errors='coerce')\n",
    "df['senior_status_date'] = pd.to_datetime(df['senior_status_date'], errors='coerce')\n",
    "\n",
    "# Step 2: Collect all relevant dates per judge\n",
    "events = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Add appointment\n",
    "    events.append({\n",
    "        'date': row['start_date'],\n",
    "        'court_name': row['court_name'],\n",
    "        'court_type': row['court_type'],\n",
    "        'party': row['nominating_party'],\n",
    "        'judge_name': row['judge_name'],\n",
    "        'change': 'add',\n",
    "        'active': True\n",
    "    })\n",
    "    # Add senior status change\n",
    "    if pd.notnull(row['senior_status_date']):\n",
    "        events.append({\n",
    "            'date': row['senior_status_date'],\n",
    "            'court_name': row['court_name'],\n",
    "            'court_type': row['court_type'],\n",
    "            'party': row['nominating_party'],\n",
    "            'judge_name': row['judge_name'],\n",
    "            'change': 'senior',\n",
    "            'active': False\n",
    "        })\n",
    "    # Add termination\n",
    "    if pd.notnull(row['termination_date']):\n",
    "        events.append({\n",
    "            'date': row['termination_date'],\n",
    "            'court_name': row['court_name'],\n",
    "            'court_type': row['court_type'],\n",
    "            'party': row['nominating_party'],\n",
    "            'judge_name': row['judge_name'],\n",
    "            'change': 'remove',\n",
    "            'active': False\n",
    "        })\n",
    "\n",
    "events_df = pd.DataFrame(events)\n",
    "events_df = events_df.sort_values('date')\n",
    "\n",
    "# Step 3: Build running totals by court/date\n",
    "\n",
    "records = []\n",
    "judge_state = defaultdict(list)  # court_id -> list of judges (dicts)\n",
    "\n",
    "for date, group in events_df.groupby('date'):\n",
    "    courts = group[['court_name', 'court_type']].drop_duplicates()\n",
    "\n",
    "    for court in courts.itertuples():\n",
    "        key = (court.court_name, court.court_type)\n",
    "\n",
    "        # Update judge state\n",
    "        for _, event in group[group['court_name'] == court.court_name].iterrows():\n",
    "            # Add appointment\n",
    "            if event['change'] == 'add':\n",
    "                judge_state[key].append({\n",
    "                    'party': event['party'],\n",
    "                    'active': True,\n",
    "                    'name': event['judge_name']  # Add name\n",
    "                })\n",
    "            # Add senior status change\n",
    "            elif event['change'] == 'senior':\n",
    "                for j in judge_state[key]:\n",
    "                    if j['party'] == event['party'] and j['active'] and j['name'] == event['judge_name']:\n",
    "                        j['active'] = False\n",
    "                        break\n",
    "            # Add termination\n",
    "            elif event['change'] == 'remove':\n",
    "                for i, j in enumerate(judge_state[key]):\n",
    "                    if j['party'] == event['party'] and j['name'] == event['judge_name']:\n",
    "                        judge_state[key].pop(i)\n",
    "                        break\n",
    "\n",
    "\n",
    "        judges = judge_state[key]\n",
    "        total_judges = len(judges)\n",
    "        total_active_judges = sum(1 for j in judges if j['active'])\n",
    "        total_dem = sum(1 for j in judges if j['party'] == 'Democratic')\n",
    "        total_rep = sum(1 for j in judges if j['party'] == 'Republican')\n",
    "        total_active_dem = sum(1 for j in judges if j['party'] == 'Democratic' and j['active'])\n",
    "        total_active_rep = sum(1 for j in judges if j['party'] == 'Republican' and j['active'])\n",
    "        judge_names = [j['name'] for j in judges]\n",
    "\n",
    "        records.append({\n",
    "            'date': date,\n",
    "            'court_name': court.court_name,\n",
    "            'court_type': court.court_type,\n",
    "            'total_judges': total_judges,\n",
    "            'total_active_judges': total_active_judges,\n",
    "            'total_dem': total_dem,\n",
    "            'total_rep': total_rep,\n",
    "            'total_active_dem': total_active_dem,\n",
    "            'total_active_rep': total_active_rep,\n",
    "            'judge_names': judge_names\n",
    "        })\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed52fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Map circuit names to numbers\n",
    "circuit_map = {\n",
    "    'First': 1,\n",
    "    'Second': 2,\n",
    "    'Third': 3,\n",
    "    'Fourth': 4,\n",
    "    'Fifth': 5,\n",
    "    'Sixth': 6,\n",
    "    'Seventh': 7,\n",
    "    'Eighth': 8,\n",
    "    'Ninth': 9,\n",
    "    'Tenth': 10,\n",
    "    'Eleventh': 11,\n",
    "    'District of Columbia': 12,\n",
    "    'Federal': 13\n",
    "}\n",
    "\n",
    "# Load shapefile (assumes it has .shp, .shx, .dbf, etc. in the same folder)\n",
    "circuits_gdf = gpd.read_file(r\"districts_map\\US Attorney Districts Shapefile_20250504\\geo_export_955d985f-a3d6-4717-9f9a-d0c540b3e5c2.shp\")\n",
    "\n",
    "# Group by 'district_n' (which represents the circuit) and dissolve into one shape per group\n",
    "# get a unique list of states for each circuit\n",
    "circuits_gdf = circuits_gdf.dissolve(\n",
    "    by='district_n',\n",
    "    as_index=False,\n",
    "    aggfunc={\n",
    "        'state': lambda x: list(set(x))\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "circuits_gdf['court_id'] = circuits_gdf['district_n']\n",
    "circuits_gdf = circuits_gdf[['court_id','state','geometry']]\n",
    "circuits_gdf['court_type'] = 'circuit'\n",
    "circuits_gdf['start_date'] = '1900-01-01'\n",
    "circuits_gdf['end_date'] = '9999-01-01'\n",
    "\n",
    "def extract_court_name(row):\n",
    "    for name, num in circuit_map.items():\n",
    "        if num == int(row['court_id'].replace('DC','12')):\n",
    "            return f'U.S. Court of Appeals for the {name} Circuit'\n",
    "    return ''\n",
    "\n",
    "circuits_gdf['court_name'] = circuits_gdf.apply(extract_court_name, axis=1)\n",
    "\n",
    "#gdf.to_json()\n",
    "\n",
    "# Or save directly to a GeoJSON file\n",
    "circuits_gdf.to_file(r\"docs\\circuits.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "circuits_df = circuits_gdf.drop(columns='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_courts = result_df.groupby(['court_type', 'court_name']).agg(\n",
    "    min_start_date=('date', 'min'),\n",
    "    max_end_date=('date', 'max')\n",
    ").reset_index()\n",
    "\n",
    "unique_courts = unique_courts.sort_values(['court_type','court_name'])\n",
    "\n",
    "# Add an ID column\n",
    "unique_courts['id'] = range(1, len(unique_courts) + 1)\n",
    "\n",
    "# Rename agg columns\n",
    "unique_courts.rename(columns={'min_start_date': 'start_date', 'max_end_date': 'end_date'}, inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "unique_courts = unique_courts[['id', 'court_type', 'court_name', 'start_date', 'end_date']]\n",
    "\n",
    "# Make manual changes to account for adding and removing certain courts.\n",
    "# When filtering for the shapes, we need to make sure the date is on or after start date and BEFORE end date.\n",
    "# Or, we may be able to just filter out zero-judge courts?\n",
    "# For now, we will make the end date of removed courts one day prior to their legislative end date.\n",
    "unique_courts.loc[unique_courts['court_name'] == 'U.S. District Court for the Eastern District of Illinois', \n",
    "                  'end_date'] = '1979-03-30' # End a day before the legislative end date\n",
    "\n",
    "# Create second iteration of District of South Carolina\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. District Court for the District of South Carolina', \n",
    "                  'end_date'] = '1911-12-31' # End a day before the legislative start date\n",
    "duplicate = unique_courts[\n",
    "                    unique_courts['court_name'] == \n",
    "                    'U.S. District Court for the District of South Carolina'].copy()\n",
    "duplicate['start_date'] = '1965-11-01' # End a day before the legislative end date\n",
    "unique_courts = pd.concat([unique_courts, duplicate], ignore_index=True)\n",
    "\n",
    "# Fix end dates for other now-defunct SC courts\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. District Court for the Eastern District of South Carolina', \n",
    "                  'end_date'] = '1965-10-31' # End a day before the legislative start date\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. District Court for the Western District of South Carolina', \n",
    "                  'end_date'] = '1965-10-31' # End a day before the legislative start date\n",
    "\n",
    "# Create second iteration of Fifth Circuit\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. Court of Appeals for the Fifth Circuit', \n",
    "                  'end_date'] = '1981-09-30' # End a day before the legislative start date\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. Court of Appeals for the Fifth Circuit', \n",
    "                  'states'] = ['Louisiana', 'Texas', 'Mississippi','Alabama','Georgia','Florida']\n",
    "duplicate = unique_courts[\n",
    "                    unique_courts['court_name'] == \n",
    "                    'U.S. Court of Appeals for the Fifth Circuit'].copy()\n",
    "duplicate['start_date'] = '1981-10-01' # Start day of legislative start date\n",
    "duplicate['states'] = ['Louisiana', 'Texas', 'Mississippi']\n",
    "unique_courts = pd.concat([unique_courts, duplicate], ignore_index=True)\n",
    "\n",
    "# Create second iteration of eighth circuit\n",
    "eighth_states = ['Nebraska', 'Minnesota', 'Iowa', 'Arkansas', 'South Dakota', 'Missouri', 'North Dakota']\n",
    "tenth_states = ['Kansas', 'Colorado', 'New Mexico', 'Utah', 'Wyoming', 'Oklahoma']\n",
    "# Create second iteration of Fifth Circuit\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. Court of Appeals for the Fifth Circuit', \n",
    "                  'end_date'] = '1929-03-27' # End a day before the legislative start date\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. Court of Appeals for the Fifth Circuit', \n",
    "                  'states'] = eighth_states + tenth_states\n",
    "duplicate = unique_courts[\n",
    "                    unique_courts['court_name'] == \n",
    "                    'U.S. Court of Appeals for the Fifth Circuit'].copy()\n",
    "duplicate['start_date'] = '1929-03-28' # Start day of legislative start date\n",
    "duplicate['states'] = eighth_states\n",
    "unique_courts = pd.concat([unique_courts, duplicate], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Extract district_name and state_name for \"U.S. District Court\"\n",
    "def extract_district_and_state(court_name):\n",
    "    if \"U.S. District Court for the\" in court_name:\n",
    "        parts = court_name.replace(\"U.S. District Court for the \", \"\").split(\" of \")\n",
    "        if len(parts) == 2:\n",
    "            if parts[1] == 'Columbia':\n",
    "                return f\"{parts[0]} of {parts[1]}\", f\"{parts[0]} of {parts[1]}\", f\"{parts[0]} of {parts[1]}\"\n",
    "            elif parts[0] == 'District':\n",
    "                return f\"{parts[0]} of {parts[1]}\", f\"{parts[0]} of {parts[1]}\", parts[1]\n",
    "            else:\n",
    "                return parts[0], f\"{parts[0]} of {parts[1]}\", parts[1]\n",
    "    return None, None, None\n",
    "\n",
    "unique_courts['partial_district'], unique_courts['full_district'], unique_courts['state_name'] = zip(\n",
    "    *unique_courts['court_name'].apply(extract_district_and_state)\n",
    ")\n",
    "\n",
    "# Add two columns with blank strings, '', called 'displayed' and 'in_box'\n",
    "unique_courts['displayed'] = ''\n",
    "unique_courts['in_box'] = ''\n",
    "\n",
    "unique_courts = unique_courts.merge(\n",
    "    circuits_df[['court_name', 'state']],\n",
    "    on='court_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "unique_courts.rename(columns={'state': 'circuit_states'}, inplace=True)\n",
    "\n",
    "# We need to fix \n",
    "\n",
    "\n",
    "unique_courts.to_csv(r\"unique_courts.csv\", index=False)\n",
    "\n",
    "# This crosswalk should indicate if the court will be displayed or not and \n",
    "# whether it will be in the little box or not.\n",
    "# It also should have notes about when each court came to be and its composition.\n",
    "# Start date for each court should be the date first judge is seated.\n",
    "\n",
    "# There are only three court districts that no longer exist.\n",
    "# the eastern district of illinois, and the western and eastern districts of SC.\n",
    "# eastern illinois ended on 1979-03-31\n",
    "# The SC districts started 1912-01-01 and ended 1965-11-01, when state went back to one district.\n",
    "# note that some senior judges remained assigned to the defunct districts for several more years\n",
    "# until their death\n",
    "\n",
    "# To generate geojson, we maybe start with Appeals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d24f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Limit to just the circuit courts\n",
    "result_df = result_df[result_df['court_type'] == 'U.S. Court of Appeals']\n",
    "\n",
    "# Apply mapping\n",
    "def extract_court_id(row):\n",
    "    if row['court_type'] == 'U.S. Court of Appeals':\n",
    "        for name, num in circuit_map.items():\n",
    "            if name in row['court_name']:\n",
    "                return f'{num}'\n",
    "    return ''\n",
    "\n",
    "result_df['court_id'] = result_df.apply(extract_court_id, axis=1)\n",
    "\n",
    "# Filter to dates on or after Jan 1, 1912\n",
    "cutoff = pd.Timestamp(\"1912-01-01\")\n",
    "\n",
    "# 1. Get latest entry before cutoff for each court\n",
    "pre_cutoff = result_df[result_df['date'] < cutoff]\n",
    "latest_pre_cutoff = pre_cutoff.sort_values('date').groupby('court_name').tail(1).copy()\n",
    "\n",
    "# 2. Set their date to the cutoff\n",
    "latest_pre_cutoff['date'] = cutoff\n",
    "\n",
    "# 3. Append to original DataFrame\n",
    "trimmed_df = pd.concat([result_df, latest_pre_cutoff], ignore_index=True)\n",
    "\n",
    "# 4. Filter out anything before the cutoff\n",
    "df = trimmed_df[trimmed_df['date'] >= cutoff].sort_values(['court_name', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Create the nested dictionary\n",
    "result = defaultdict(dict)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    court_id = row['court_id']\n",
    "    date_str = row['date'].strftime('%Y-%m-%d')\n",
    "    rep_percentage = row['total_active_rep'] / row['total_active_judges'] if row['total_active_judges'] > 0 else 0\n",
    "    result[court_id][date_str] = [row['total_judges'],rep_percentage]\n",
    "\n",
    "# Convert to regular dict for JSON output\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "# Optional: Save to file\n",
    "with open('docs\\\\court_judges.json', 'w') as f:\n",
    "    f.write(json_output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
