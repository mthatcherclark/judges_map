{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "judges_url = 'https://www.fjc.gov/sites/default/files/history/federal-judicial-service.csv'\n",
    "\n",
    "judges_df_download = pd.read_csv(judges_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a412d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix nominating_party values that start with \"None\"\n",
    "# If there is no nominating party (usually because of a recess appointment that did not result in a commission),\n",
    "# use the last nominating party\n",
    "def fix_nominating_party(row):\n",
    "    if row['nominating_party'].startswith(\"None\"):\n",
    "        previous_rows = judges_df[(judges_df['nid'] == row['nid']) & (judges_df['start_date'] < row['start_date'])]\n",
    "        if not previous_rows.empty:\n",
    "            last_valid_row = previous_rows[~previous_rows['nominating_party'].str.startswith(\"None\")].sort_values('start_date', ascending=False).head(1)\n",
    "            if not last_valid_row.empty:\n",
    "                return last_valid_row['nominating_party'].values[0]\n",
    "    return row['nominating_party']\n",
    "\n",
    "# Preserve the original to avoid requesting the data again\n",
    "judges_df = judges_df_download.copy()\n",
    "\n",
    "judges_df.columns = judges_df.columns.str.lower().str.replace(' ', '_').str.replace('/', '_').str.replace(',', '_')\n",
    "\n",
    "judges_df['start_date'] = judges_df['recess_appointment_date'].fillna(judges_df['commission_date'])\n",
    "judges_df['nominating_party'] = judges_df['party_of_reappointing_president'].fillna(judges_df['party_of_appointing_president']).fillna(\"George Washington\")\n",
    "\n",
    "judges_df['nominating_party'] = judges_df.apply(fix_nominating_party, axis=1)\n",
    "\n",
    "# Eliminate the courts that we do not want.\n",
    "# Courts of Appeals started in 1911. So, our start date will be Jan. 1, 1912.\n",
    "judges_df = judges_df[judges_df['court_type'].isin([\"Supreme Court\", \"U.S. District Court\", \"U.S. Court of Appeals\"])]\n",
    "\n",
    "# Make sure date columns are datetime\n",
    "judges_df['start_date'] = pd.to_datetime(judges_df['start_date'])\n",
    "judges_df['termination_date'] = pd.to_datetime(judges_df['termination_date'])\n",
    "judges_df['senior_status_date'] = pd.to_datetime(judges_df['senior_status_date'])\n",
    "\n",
    "# Define the cutoff date\n",
    "cutoff = pd.Timestamp('1912-01-01')\n",
    "\n",
    "# Filter to judges serving on the cutoff date or later\n",
    "judges_df = judges_df[\n",
    "    (((judges_df['start_date'] <= cutoff) & ((judges_df['termination_date'].isna()) | (judges_df['termination_date'] >= cutoff)))\n",
    "     | (judges_df['start_date'] > cutoff))\n",
    "]\n",
    "\n",
    "# Some helpful comparisons, at least for circuit courts:\n",
    "# https://www.acslaw.org/judicial-nominations/change-in-court-composition/\n",
    "# https://www.reddit.com/r/MapPorn/comments/18uxvdk/partisan_composition_of_every_district_courts/\n",
    "# https://en.wikipedia.org/wiki/Judicial_appointment_history_for_United_States_federal_courts#:~:text=As%20of%20January%202%2C%202025%2C%20of%20the%20679%20district%20court,a%20majority%20in%204%20circuits.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ca544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for active First Circuit judges\n",
    "active_first_circuit = judges_df[\n",
    "    (judges_df['court_name'] == 'U.S. Court of Appeals for the Second Circuit') &\n",
    "    (judges_df['termination_date'].isna()) &\n",
    "    (judges_df['senior_status_date'].isna())\n",
    "]\n",
    "\n",
    "# Count by nominating party\n",
    "party_counts = active_first_circuit['nominating_party'].value_counts(dropna=False)\n",
    "total = party_counts.sum()\n",
    "\n",
    "# Create summary DataFrame\n",
    "party_summary = party_counts.reset_index()\n",
    "party_summary.columns = ['party', 'count']\n",
    "party_summary['percentage'] = (party_summary['count'] / total * 100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82dfd86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maplibre import Layer, LayerType, Map, MapOptions\n",
    "from maplibre.sources import GeoJSONSource\n",
    "from maplibre.utils import df_to_geojson, geopandas_to_geojson\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "\n",
    "# --- 1. Generate Fake Home Data ---\n",
    "NUM_HOMES = 100\n",
    "CENTER_LAT = 21.3069  # Honolulu Latitude\n",
    "CENTER_LON = -157.8583 # Honolulu Longitude\n",
    "RADIUS = 0.05 # Degree radius for random points\n",
    "\n",
    "lats = []\n",
    "lons = []\n",
    "for_sale_status = []\n",
    "ids = []\n",
    "\n",
    "for i in range(NUM_HOMES):\n",
    "    lat = CENTER_LAT + random.uniform(-RADIUS, RADIUS)\n",
    "    lon = CENTER_LON + random.uniform(-RADIUS, RADIUS)\n",
    "    for_sale = random.choice([True, False])\n",
    "\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    for_sale_status.append(for_sale)\n",
    "    ids.append(f\"home_{i}\")\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'latitude': lats,\n",
    "    'longitude': lons,\n",
    "    'for_sale': for_sale_status\n",
    "})\n",
    "\n",
    "# --- 2. Create GeoDataFrame ---\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "    crs=\"EPSG:4326\" # WGS 84 coordinate system\n",
    ")\n",
    "\n",
    "# Convert to GEOJSON and as source\n",
    "gdf_json1 = gdf.to_json()\n",
    "with open(\"homes_data.geojson\", \"w\") as file:\n",
    "    file.write(gdf_json1)\n",
    "\n",
    "\n",
    "#gdf_json2 = geopandas_to_geojson(gdf) # This one works because it requires dictionary\n",
    "\n",
    "\n",
    "# homes = GeoJSONSource(data=geopandas_to_geojson(gdf))\n",
    "\n",
    "# map_options = MapOptions(\n",
    "#     center=(CENTER_LON, CENTER_LAT),\n",
    "#     zoom=12,\n",
    "#     hash=True,\n",
    "# )\n",
    "\n",
    "# m = Map(map_options)\n",
    "# m.add_layer(\n",
    "#     Layer(\n",
    "#         id='homes1',\n",
    "#         type=LayerType.CIRCLE,\n",
    "#         source=homes,\n",
    "#         paint={\n",
    "#             \"circle-color\": [\"match\", [\"get\", \"for_sale\"], 1, 'red', 'blue'],\n",
    "#             \"circle-radius\": 5,\n",
    "#         },\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# out_filename = 'home.html'\n",
    "# with open(out_filename, \"w\") as f:\n",
    "#     f.write(m.to_html())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
