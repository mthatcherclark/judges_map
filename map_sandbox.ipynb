{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffcf01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "judges_url = 'https://www.fjc.gov/sites/default/files/history/federal-judicial-service.csv'\n",
    "\n",
    "judges_df_download = pd.read_csv(judges_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a412d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix nominating_party values that start with \"None\"\n",
    "# If there is no nominating party (usually because of a recess appointment that did not result in a commission),\n",
    "# use the last nominating party\n",
    "def fix_nominating_party(row):\n",
    "    if row['nominating_party'].startswith(\"None\"):\n",
    "        previous_rows = judges_df[(judges_df['nid'] == row['nid']) & (judges_df['start_date'] < row['start_date'])]\n",
    "        if not previous_rows.empty:\n",
    "            last_valid_row = previous_rows[~previous_rows['nominating_party'].str.startswith(\"None\")].sort_values('start_date', ascending=False).head(1)\n",
    "            if not last_valid_row.empty:\n",
    "                return last_valid_row['nominating_party'].values[0]\n",
    "    return row['nominating_party']\n",
    "\n",
    "# Preserve the original to avoid requesting the data again\n",
    "judges_df = judges_df_download.copy()\n",
    "\n",
    "judges_df.columns = judges_df.columns.str.lower().str.replace(' ', '_').str.replace('/', '_').str.replace(',', '_')\n",
    "\n",
    "judges_df['start_date'] = judges_df['recess_appointment_date'].fillna(judges_df['commission_date'])\n",
    "judges_df['nominating_party'] = judges_df['party_of_reappointing_president'].fillna(judges_df['party_of_appointing_president']).fillna(\"George Washington\")\n",
    "\n",
    "judges_df['nominating_party'] = judges_df.apply(fix_nominating_party, axis=1)\n",
    "\n",
    "# Eliminate the courts that we do not want.\n",
    "# Courts of Appeals started in 1911. So, our start date will be Jan. 1, 1912.\n",
    "judges_df = judges_df[judges_df['court_type'].isin([\"Supreme Court\", \"U.S. District Court\", \"U.S. Court of Appeals\"])]\n",
    "\n",
    "# Make sure date columns are datetime\n",
    "judges_df['start_date'] = pd.to_datetime(judges_df['start_date'])\n",
    "judges_df['termination_date'] = pd.to_datetime(judges_df['termination_date'])\n",
    "judges_df['senior_status_date'] = pd.to_datetime(judges_df['senior_status_date'])\n",
    "\n",
    "# Define the cutoff date\n",
    "cutoff = pd.Timestamp('1912-01-01')\n",
    "\n",
    "# Filter to judges serving on the cutoff date or later\n",
    "judges_df = judges_df[\n",
    "    (((judges_df['start_date'] <= cutoff) & ((judges_df['termination_date'].isna()) | (judges_df['termination_date'] >= cutoff)))\n",
    "     | (judges_df['start_date'] > cutoff))\n",
    "]\n",
    "\n",
    "# Some helpful comparisons, at least for circuit courts:\n",
    "# https://www.acslaw.org/judicial-nominations/change-in-court-composition/\n",
    "# https://www.reddit.com/r/MapPorn/comments/18uxvdk/partisan_composition_of_every_district_courts/\n",
    "# https://en.wikipedia.org/wiki/Judicial_appointment_history_for_United_States_federal_courts#:~:text=As%20of%20January%202%2C%202025%2C%20of%20the%20679%20district%20court,a%20majority%20in%204%20circuits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c1febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is called `df`\n",
    "# and columns: start_date, termination_date, senior_status_date, nominating_party, court_name, court_type\n",
    "\n",
    "# Step 1: Parse dates\n",
    "df = judges_df.copy()\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df['termination_date'] = pd.to_datetime(df['termination_date'], errors='coerce')\n",
    "df['senior_status_date'] = pd.to_datetime(df['senior_status_date'], errors='coerce')\n",
    "\n",
    "# Step 2: Collect all relevant dates per judge\n",
    "events = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Add appointment\n",
    "    events.append({\n",
    "        'date': row['start_date'],\n",
    "        'court_name': row['court_name'],\n",
    "        'court_type': row['court_type'],\n",
    "        'party': row['nominating_party'],\n",
    "        'judge_name': row['judge_name'],\n",
    "        'change': 'add',\n",
    "        'active': True\n",
    "    })\n",
    "    # Add senior status change\n",
    "    if pd.notnull(row['senior_status_date']):\n",
    "        events.append({\n",
    "            'date': row['senior_status_date'],\n",
    "            'court_name': row['court_name'],\n",
    "            'court_type': row['court_type'],\n",
    "            'party': row['nominating_party'],\n",
    "            'judge_name': row['judge_name'],\n",
    "            'change': 'senior',\n",
    "            'active': False\n",
    "        })\n",
    "    # Add termination\n",
    "    if pd.notnull(row['termination_date']):\n",
    "        events.append({\n",
    "            'date': row['termination_date'],\n",
    "            'court_name': row['court_name'],\n",
    "            'court_type': row['court_type'],\n",
    "            'party': row['nominating_party'],\n",
    "            'judge_name': row['judge_name'],\n",
    "            'change': 'remove',\n",
    "            'active': False\n",
    "        })\n",
    "\n",
    "events_df = pd.DataFrame(events)\n",
    "events_df = events_df.sort_values('date')\n",
    "\n",
    "# Step 3: Build running totals by court/date\n",
    "from collections import defaultdict\n",
    "\n",
    "records = []\n",
    "judge_state = defaultdict(list)  # court_id -> list of judges (dicts)\n",
    "\n",
    "for date, group in events_df.groupby('date'):\n",
    "    courts = group[['court_name', 'court_type']].drop_duplicates()\n",
    "\n",
    "    for court in courts.itertuples():\n",
    "        key = (court.court_name, court.court_type)\n",
    "\n",
    "        # Update judge state\n",
    "        for _, event in group[group['court_name'] == court.court_name].iterrows():\n",
    "            # Add appointment\n",
    "            if event['change'] == 'add':\n",
    "                judge_state[key].append({\n",
    "                    'party': event['party'],\n",
    "                    'active': True,\n",
    "                    'name': event['judge_name']  # Add name\n",
    "                })\n",
    "            # Add senior status change\n",
    "            elif event['change'] == 'senior':\n",
    "                for j in judge_state[key]:\n",
    "                    if j['party'] == event['party'] and j['active'] and j['name'] == event['judge_name']:\n",
    "                        j['active'] = False\n",
    "                        break\n",
    "            # Add termination\n",
    "            elif event['change'] == 'remove':\n",
    "                for i, j in enumerate(judge_state[key]):\n",
    "                    if j['party'] == event['party'] and j['name'] == event['judge_name']:\n",
    "                        judge_state[key].pop(i)\n",
    "                        break\n",
    "\n",
    "\n",
    "        judges = judge_state[key]\n",
    "        total_judges = len(judges)\n",
    "        total_active_judges = sum(1 for j in judges if j['active'])\n",
    "        total_dem = sum(1 for j in judges if j['party'] == 'Democratic')\n",
    "        total_rep = sum(1 for j in judges if j['party'] == 'Republican')\n",
    "        total_active_dem = sum(1 for j in judges if j['party'] == 'Democratic' and j['active'])\n",
    "        total_active_rep = sum(1 for j in judges if j['party'] == 'Republican' and j['active'])\n",
    "        judge_names = [j['name'] for j in judges]\n",
    "\n",
    "        records.append({\n",
    "            'date': date,\n",
    "            'court_name': court.court_name,\n",
    "            'court_type': court.court_type,\n",
    "            'total_judges': total_judges,\n",
    "            'total_active_judges': total_active_judges,\n",
    "            'total_dem': total_dem,\n",
    "            'total_rep': total_rep,\n",
    "            'total_active_dem': total_active_dem,\n",
    "            'total_active_rep': total_active_rep,\n",
    "            'judge_names': judge_names\n",
    "        })\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "\n",
    "# Limit to just the circuit courts\n",
    "result_df = result_df[result_df['court_type'] == 'U.S. Court of Appeals']\n",
    "\n",
    "# Map circuit names to numbers\n",
    "circuit_map = {\n",
    "    'First': 1,\n",
    "    'Second': 2,\n",
    "    'Third': 3,\n",
    "    'Fourth': 4,\n",
    "    'Fifth': 5,\n",
    "    'Sixth': 6,\n",
    "    'Seventh': 7,\n",
    "    'Eighth': 8,\n",
    "    'Ninth': 9,\n",
    "    'Tenth': 10,\n",
    "    'Eleventh': 11,\n",
    "    'District of Columbia': 12,\n",
    "    'Federal': 13\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "def extract_court_id(row):\n",
    "    if row['court_type'] == 'U.S. Court of Appeals':\n",
    "        for name, num in circuit_map.items():\n",
    "            if name in row['court_name']:\n",
    "                return f'{num}'\n",
    "    return ''\n",
    "\n",
    "result_df['court_id'] = result_df.apply(extract_court_id, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d24f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "df = result_df.copy()\n",
    "\n",
    "# Filter to dates on or after Jan 1, 1912\n",
    "df = df[df['date'] >= '1912-01-01']\n",
    "\n",
    "# Create the nested dictionary\n",
    "result = defaultdict(dict)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    court_id = row['court_id']\n",
    "    date_str = row['date'].strftime('%Y-%m-%d')\n",
    "    result[court_id][date_str] = [row['total_judges']]\n",
    "\n",
    "# Convert to regular dict for JSON output\n",
    "json_output = json.dumps(result, indent=2)\n",
    "\n",
    "# Optional: Save to file\n",
    "with open('docs\\\\court_judges.json', 'w') as f:\n",
    "    f.write(json_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ade0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  court_id abbr                          name  \\\n",
      "0        1   ME             District of Maine   \n",
      "1       10   CO          District of Colorado   \n",
      "2       11  ALM    Middle District of Alabama   \n",
      "3        2  NYW  Western District of New York   \n",
      "4        3   NJ        District of New Jersey   \n",
      "\n",
      "                                            geometry court_type  start_date  \\\n",
      "0  MULTIPOLYGON (((-71.55556 41.20832, -71.55795 ...    circuit  1900-01-01   \n",
      "1  POLYGON ((-103.04193 36.50036, -103.04175 36.3...    circuit  1900-01-01   \n",
      "2  MULTIPOLYGON (((-82.87366 24.62647, -82.8752 2...    circuit  1900-01-01   \n",
      "3  MULTIPOLYGON (((-74.0676 40.62387, -74.06315 4...    circuit  1900-01-01   \n",
      "4  MULTIPOLYGON (((-65.00283 18.30503, -65.00254 ...    circuit  1900-01-01   \n",
      "\n",
      "     end_date  \n",
      "0  2020-01-01  \n",
      "1  2020-01-01  \n",
      "2  2020-01-01  \n",
      "3  2020-01-01  \n",
      "4  2020-01-01  \n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load shapefile (assumes it has .shp, .shx, .dbf, etc. in the same folder)\n",
    "gdf = gpd.read_file(r\"districts_map\\US Attorney Districts Shapefile_20250504\\geo_export_955d985f-a3d6-4717-9f9a-d0c540b3e5c2.shp\")\n",
    "\n",
    "# Group by 'district_n' (which represents the circuit) and dissolve into one shape per group\n",
    "circuits_gdf = gdf.dissolve(by='district_n', as_index=False)\n",
    "\n",
    "circuits_gdf['court_id'] = circuits_gdf['district_n']\n",
    "circuits_gdf = circuits_gdf[['court_id', 'abbr','name','geometry']]\n",
    "circuits_gdf['court_type'] = 'circuit'\n",
    "circuits_gdf['start_date'] = '1900-01-01'\n",
    "circuits_gdf['end_date'] = '9999-01-01'\n",
    "\n",
    "#gdf.to_json()\n",
    "\n",
    "# Or save directly to a GeoJSON file\n",
    "circuits_gdf.to_file(r\"docs\\circuits.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(circuits_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dfd86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maplibre import Layer, LayerType, Map, MapOptions\n",
    "from maplibre.sources import GeoJSONSource\n",
    "from maplibre.utils import df_to_geojson, geopandas_to_geojson\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "\n",
    "# --- 1. Generate Fake Home Data ---\n",
    "NUM_HOMES = 100\n",
    "CENTER_LAT = 21.3069  # Honolulu Latitude\n",
    "CENTER_LON = -157.8583 # Honolulu Longitude\n",
    "RADIUS = 0.05 # Degree radius for random points\n",
    "\n",
    "lats = []\n",
    "lons = []\n",
    "for_sale_status = []\n",
    "year_built_status = []\n",
    "ids = []\n",
    "\n",
    "for i in range(NUM_HOMES):\n",
    "    lat = CENTER_LAT + random.uniform(-RADIUS, RADIUS)\n",
    "    lon = CENTER_LON + random.uniform(-RADIUS, RADIUS)\n",
    "    for_sale = random.choice([True, False])\n",
    "    year_built = random.randint(1900, 2023)\n",
    "\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    for_sale_status.append(for_sale)\n",
    "    year_built_status.append(year_built)\n",
    "    ids.append(f\"home_{i}\")\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'latitude': lats,\n",
    "    'longitude': lons,\n",
    "    'for_sale': for_sale_status,\n",
    "    'year_built': year_built_status\n",
    "})\n",
    "\n",
    "# --- 2. Create GeoDataFrame ---\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "    crs=\"EPSG:4326\" # WGS 84 coordinate system\n",
    ")\n",
    "\n",
    "# Convert to GEOJSON and as source\n",
    "gdf_json1 = gdf.to_json()\n",
    "with open(\"docs\\homes_data.geojson\", \"w\") as file:\n",
    "    file.write(gdf_json1)\n",
    "\n",
    "\n",
    "#gdf_json2 = geopandas_to_geojson(gdf) # This one works because it requires dictionary\n",
    "\n",
    "\n",
    "# homes = GeoJSONSource(data=geopandas_to_geojson(gdf))\n",
    "\n",
    "# map_options = MapOptions(\n",
    "#     center=(CENTER_LON, CENTER_LAT),\n",
    "#     zoom=12,\n",
    "#     hash=True,\n",
    "# )\n",
    "\n",
    "# m = Map(map_options)\n",
    "# m.add_layer(\n",
    "#     Layer(\n",
    "#         id='homes1',\n",
    "#         type=LayerType.CIRCLE,\n",
    "#         source=homes,\n",
    "#         paint={\n",
    "#             \"circle-color\": [\"match\", [\"get\", \"for_sale\"], 1, 'red', 'blue'],\n",
    "#             \"circle-radius\": 5,\n",
    "#         },\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# out_filename = 'home.html'\n",
    "# with open(out_filename, \"w\") as f:\n",
    "#     f.write(m.to_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Load the GeoJSON data\n",
    "gdf_data = json.loads(gdf_json1)\n",
    "\n",
    "# Extract the 'year_built' property from each feature\n",
    "year_built_list = [feature['properties']['year_built'] for feature in gdf_data['features']]\n",
    "\n",
    "# Count the occurrences of each year1933\n",
    "year_counts = Counter(year_built_list)\n",
    "\n",
    "# Sort the counts in descending order\n",
    "sorted_year_counts = sorted(year_counts.items(), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Print the sorted list\n",
    "for year, count in sorted_year_counts:\n",
    "    print(f\"Year: {year}, Count: {count}\")\n",
    "\n",
    "\n",
    "\n",
    "# so we are going to be displaying polygons shaded by the percentage red or blue\n",
    "# there are different polygons for district and circuit and these can change over time\n",
    "# the districts changed each decade, affecting the circuit shape\n",
    "# further the circuit (5) became two (11 and 5) in 1981\n",
    "# We also want the user to be able to include or exclude senior judges\n",
    "# So, if we want to go back to the start of the court of appeals in 1911,\n",
    "# we will have ten sets of polygons for circuit (12-13) and district (94)\n",
    "# So, like 1,100 polygons in the GeoJSON file\n",
    "# AI suggests having one GEOJSON for the shapes and another for the data.\n",
    "# The data would have an entry for each of the roughly 46,000 days\n",
    "# Each day would have a district_id, circuit_id,\n",
    "# number of active judges for each party and number of active+senior judges for each party\n",
    "\n",
    "# Use this map for 2004 when Northern Mariana Islands was added to the 9th Circuit...\n",
    "# https://data.ojp.usdoj.gov/Shapefile/US-Attorney-Districts-Shapefile/5fdt-n5ne/about_data\n",
    "# We may need to let the data dictate when new districts, etc. were added\n",
    "\n",
    "\n",
    "# We may have to have a box that displays things like Supreme Court, territories, DC, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
