{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c614e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Script assumes maps/simplified has the geojson files for creating court shapes\n",
    "\n",
    "# Some possibly helpful comparisons....\n",
    "# https://www.acslaw.org/judicial-nominations/change-in-court-composition/\n",
    "# https://www.reddit.com/r/MapPorn/comments/18uxvdk/partisan_composition_of_every_district_courts/\n",
    "# https://en.wikipedia.org/wiki/Judicial_appointment_history_for_United_States_federal_courts#:~:text=As%20of%20January%202%2C%202025%2C%20of%20the%20679%20district%20court,a%20majority%20in%204%20circuits.\n",
    "# https://www.brookings.edu/articles/how-much-will-trumps-second-term-judicial-appointments-shift-court-balance/\n",
    "\n",
    "judges_url = 'https://www.fjc.gov/sites/default/files/history/federal-judicial-service.csv'\n",
    "\n",
    "judges_df_download = pd.read_csv(judges_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcf01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nominating_party(row):\n",
    "    '''\n",
    "    Fix nominating_party values that start with \"None\"\n",
    "    If there is no nominating party (usually because of a recess appointment that did not result in a commission),\n",
    "    use the last nominating party\n",
    "    '''\n",
    "    if row['nominating_party'].startswith(\"None\"):\n",
    "        previous_rows = judges_df[(judges_df['nid'] == row['nid']) & (judges_df['start_date'] < row['start_date'])]\n",
    "        if not previous_rows.empty:\n",
    "            last_valid_row = previous_rows[~previous_rows['nominating_party'].str.startswith(\"None\")].sort_values('start_date', ascending=False).head(1)\n",
    "            if not last_valid_row.empty:\n",
    "                return last_valid_row['nominating_party'].values[0]\n",
    "    return row['nominating_party']\n",
    "\n",
    "# Define the cutoff date\n",
    "# The start of Ronald Reagan's presidency\n",
    "# shortly before 5th circuit was subdivided, creating 11th\n",
    "cutoff = pd.Timestamp('1981-01-20')\n",
    "\n",
    "# Preserve the original to avoid requesting the data again\n",
    "judges_df = judges_df_download.copy()\n",
    "\n",
    "# Fixing column headers by removing spaces, slashes and commas\n",
    "judges_df.columns = judges_df.columns.str.lower().str.replace(' ', '_').str.replace('/', '_').str.replace(',', '_')\n",
    "\n",
    "# The District Court of the District of Columbia was known by Supreme Court of the District of Columbia until 1936-ish\n",
    "# We will just call it the District Court of the District of Columbia throughout the data.\n",
    "judges_df['court_name'] = judges_df['court_name'].replace(r\"U.S. District Court for the District of Columbia (Supreme Court of the District of Columbia)\", \"U.S. District Court for the District of Columbia\")\n",
    "\n",
    "# start date is either recess appointment date or commission date\n",
    "judges_df['start_date'] = judges_df['recess_appointment_date'].fillna(judges_df['commission_date'])\n",
    "\n",
    "# Note: most recent start date for judge without DEM/GOP nominating party is in 1886, Whig party\n",
    "# Nominating party is the reappointing president, the appointing president if appointed on first try or George Washington if null.\n",
    "judges_df['nominating_party'] = judges_df['party_of_reappointing_president'].fillna(judges_df['party_of_appointing_president']).fillna(\"George Washington\")\n",
    "# Except some were recess appointments and had None as the nominating party because it was a recess appointment. We apply the party of the last appointment.\n",
    "judges_df['nominating_party'] = judges_df.apply(fix_nominating_party, axis=1)\n",
    "\n",
    "# Eliminate the courts that we do not want.\n",
    "# Circuit courts ended in 1911.\n",
    "# \"Supreme Court\", \n",
    "judges_df = judges_df[\n",
    "    judges_df['court_type'].isin([\"U.S. District Court\", \"U.S. Court of Appeals\"]) &\n",
    "    (judges_df['court_name'] != \"U.S. Court of Appeals for the Federal Circuit\")\n",
    "]\n",
    "\n",
    "# Make sure date columns are datetime\n",
    "judges_df['start_date'] = pd.to_datetime(judges_df['start_date'])\n",
    "judges_df['termination_date'] = pd.to_datetime(judges_df['termination_date'])\n",
    "judges_df['senior_status_date'] = pd.to_datetime(judges_df['senior_status_date'])\n",
    "\n",
    "# Filter to judges serving on the cutoff date or later\n",
    "judges_df = judges_df[\n",
    "    (((judges_df['start_date'] <= cutoff) & ((judges_df['termination_date'].isna()) | (judges_df['termination_date'] >= cutoff)))\n",
    "     | (judges_df['start_date'] > cutoff))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c1febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Now, we identify all the events, \n",
    "# including appointments, senior status changes, and terminations.\n",
    "\n",
    "# Step 1: Copy the judges_df\n",
    "df = judges_df.copy()\n",
    "\n",
    "# Step 2: Collect all relevant dates per judge\n",
    "events = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Add appointment\n",
    "    events.append({\n",
    "        'date': row['start_date'],\n",
    "        'court_name': row['court_name'],\n",
    "        'court_type': row['court_type'],\n",
    "        'party': row['nominating_party'],\n",
    "        'judge_name': row['judge_name'],\n",
    "        'change': 'add',\n",
    "        'active': True\n",
    "    })\n",
    "    # Add senior status change\n",
    "    if pd.notnull(row['senior_status_date']):\n",
    "        events.append({\n",
    "            'date': row['senior_status_date'],\n",
    "            'court_name': row['court_name'],\n",
    "            'court_type': row['court_type'],\n",
    "            'party': row['nominating_party'],\n",
    "            'judge_name': row['judge_name'],\n",
    "            'change': 'senior',\n",
    "            'active': False\n",
    "        })\n",
    "    # Add termination\n",
    "    if pd.notnull(row['termination_date']):\n",
    "        events.append({\n",
    "            'date': row['termination_date'],\n",
    "            'court_name': row['court_name'],\n",
    "            'court_type': row['court_type'],\n",
    "            'party': row['nominating_party'],\n",
    "            'judge_name': row['judge_name'],\n",
    "            'change': 'remove',\n",
    "            'active': False\n",
    "        })\n",
    "\n",
    "events_df = pd.DataFrame(events)\n",
    "events_df = events_df.sort_values('date')\n",
    "\n",
    "# Step 3: Build running totals by court/date\n",
    "records = []\n",
    "judge_state = defaultdict(list)  # court_id -> list of judges (dicts)\n",
    "\n",
    "for date, group in events_df.groupby('date'):\n",
    "    courts = group[['court_name', 'court_type']].drop_duplicates()\n",
    "\n",
    "    for court in courts.itertuples():\n",
    "        key = (court.court_name, court.court_type)\n",
    "\n",
    "        # Update judge state\n",
    "        for _, event in group[group['court_name'] == court.court_name].iterrows():\n",
    "            # Add appointment\n",
    "            if event['change'] == 'add':\n",
    "                judge_state[key].append({\n",
    "                    'party': event['party'],\n",
    "                    'active': True,\n",
    "                    'name': event['judge_name']  # Add name\n",
    "                })\n",
    "            # Add senior status change\n",
    "            elif event['change'] == 'senior':\n",
    "                for j in judge_state[key]:\n",
    "                    if j['party'] == event['party'] and j['active'] and j['name'] == event['judge_name']:\n",
    "                        j['active'] = False\n",
    "                        break\n",
    "            # Add termination\n",
    "            elif event['change'] == 'remove':\n",
    "                for i, j in enumerate(judge_state[key]):\n",
    "                    if j['party'] == event['party'] and j['name'] == event['judge_name']:\n",
    "                        judge_state[key].pop(i)\n",
    "                        break\n",
    "\n",
    "        # Note: most recent start date for judge without DEM/GOP nominating party is in 1886, Whig party\n",
    "        judges = judge_state[key]\n",
    "        total_judges = len(judges)\n",
    "        total_active_judges = sum(1 for j in judges if j['active'])\n",
    "        total_dem = sum(1 for j in judges if j['party'] == 'Democratic')\n",
    "        total_rep = sum(1 for j in judges if j['party'] == 'Republican')\n",
    "        total_active_dem = sum(1 for j in judges if j['party'] == 'Democratic' and j['active'])\n",
    "        total_active_rep = sum(1 for j in judges if j['party'] == 'Republican' and j['active'])\n",
    "        judge_names = [j['name'] for j in judges]\n",
    "\n",
    "        records.append({\n",
    "            'date': date,\n",
    "            'court_name': court.court_name,\n",
    "            'court_type': court.court_type,\n",
    "            'total_judges': total_judges,\n",
    "            'total_active_judges': total_active_judges,\n",
    "            'total_dem': total_dem,\n",
    "            'total_rep': total_rep,\n",
    "            'total_active_dem': total_active_dem,\n",
    "            'total_active_rep': total_active_rep,\n",
    "            'judge_names': judge_names\n",
    "        })\n",
    "\n",
    "result_df = pd.DataFrame(records)\n",
    "\n",
    "# Ensure the first event for each court_name has the cutoff date\n",
    "first_event_date = cutoff\n",
    "\n",
    "# Group by court_name and find the most recent event on or before cutoff\n",
    "adjusted_records = []\n",
    "for court_name, group in result_df.groupby('court_name'):\n",
    "    group_before_cutoff = group[group['date'] <= first_event_date]\n",
    "    if not group_before_cutoff.empty:\n",
    "        latest_event = group_before_cutoff.iloc[-1]\n",
    "        adjusted_record = latest_event.copy()\n",
    "        adjusted_record['date'] = first_event_date\n",
    "        adjusted_records.append(adjusted_record)\n",
    "\n",
    "# Remove records on or before cutoff\n",
    "result_df = result_df[result_df['date'] > first_event_date]\n",
    "\n",
    "# Add the adjusted records to the result_df\n",
    "if adjusted_records:\n",
    "    adjusted_df = pd.DataFrame(adjusted_records)\n",
    "    result_df = pd.concat([result_df, adjusted_df], ignore_index=True)\n",
    "\n",
    "# Sort the result_df by date again\n",
    "result_df = result_df.sort_values('date').reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b440d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling a unique list of court iterations\n",
    "\n",
    "# There are only three court districts that no longer exist (since at least 1912).\n",
    "# the eastern district of illinois, and the western and eastern districts of SC.\n",
    "# eastern illinois ended on 1979-03-31\n",
    "# The SC districts started 1912-01-01 and ended 1965-11-01, when state went back to one district.\n",
    "# note that some senior judges remained assigned to the defunct districts for several more years\n",
    "# until their death\n",
    "\n",
    "appeals_court_states = {\n",
    "'U.S. Court of Appeals for the District of Columbia Circuit': ['District of Columbia'],\n",
    "'U.S. Court of Appeals for the Eighth Circuit': ['Nebraska', 'Minnesota', 'Iowa', 'Arkansas', 'South Dakota', 'Missouri', 'North Dakota'],\n",
    "'U.S. Court of Appeals for the Eleventh Circuit': ['Alabama', 'Georgia', 'Florida'],\n",
    "'U.S. Court of Appeals for the Fifth Circuit': ['Louisiana', 'Texas', 'Mississippi'],\n",
    "'U.S. Court of Appeals for the First Circuit': ['Rhode Island', 'New Hampshire', 'Massachusetts', 'Maine', 'Puerto Rico'],\n",
    "'U.S. Court of Appeals for the Fourth Circuit': ['Maryland', 'South Carolina', 'West Virginia', 'North Carolina', 'Virginia'],\n",
    "'U.S. Court of Appeals for the Ninth Circuit': ['Montana', 'Washington', 'Idaho', 'Arizona', 'Nevada', 'Alaska', 'California', 'Oregon', 'Hawaii', 'Guam', 'Northern Marianas Islands'],\n",
    "'U.S. Court of Appeals for the Second Circuit': ['Vermont', 'Connecticut', 'New York'],\n",
    "'U.S. Court of Appeals for the Seventh Circuit': ['Wisconsin', 'Illinois', 'Indiana'],\n",
    "'U.S. Court of Appeals for the Sixth Circuit': ['Tennessee', 'Ohio', 'Kentucky', 'Michigan'],\n",
    "'U.S. Court of Appeals for the Tenth Circuit': ['Kansas', 'Colorado', 'New Mexico', 'Utah', 'Wyoming', 'Oklahoma'],\n",
    "'U.S. Court of Appeals for the Third Circuit': ['US Virgin Islands', 'Pennsylvania', 'New Jersey', 'Delaware'],\n",
    "}\n",
    "\n",
    "unique_courts = result_df.groupby(['court_type', 'court_name']).agg(\n",
    "    min_start_date=('date', 'min'),\n",
    "    max_end_date=('date', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Rename agg columns\n",
    "unique_courts.rename(columns={'min_start_date': 'start_date', 'max_end_date': 'end_date'}, inplace=True)\n",
    "\n",
    "# Assign the correct states to the circuit courts\n",
    "# Note that New Mexico, Arizona, Alaska, Hawaii and Puerto Rico became states/got districts\n",
    "# as long ago as 1910, but we largely ignore this due to a much later cutoff date, for now (possibly).\n",
    "unique_courts['states'] = [[] for _ in range(len(unique_courts))] # Initialize with empty lists\n",
    "unique_courts['states'] = unique_courts['court_name'].map(appeals_court_states).combine_first(unique_courts['states'])\n",
    "\n",
    "good_courts = unique_courts.copy()\n",
    "\n",
    "# Make manual changes to account for adding and removing certain courts.\n",
    "# Start/end dates are somtimes one day before/after the legislative start/end dates\n",
    "# to distinguish them from other affected courts.\n",
    "# However, remember that the start/end dates are also driven by when judges were actually\n",
    "# seated in a new court.\n",
    "# The below is largely ignored (and incomplete) due to the \n",
    "# later cutoff date, but we will keep it for now.\n",
    "\n",
    "# Indiana was subdivided into two districts\n",
    "unique_courts.loc[unique_courts['court_name'] == 'U.S. District Court for the District of Indiana', \n",
    "                  'end_date'] = pd.to_datetime('1928-04-20') # End a day before the legislative end date\n",
    "\n",
    "# Replaced with another district\n",
    "unique_courts.loc[unique_courts['court_name'] == 'U.S. District Court for the Eastern District of Illinois', \n",
    "                  'end_date'] = pd.to_datetime('1979-03-30') # End a day before the legislative end date\n",
    "\n",
    "# Modify District of South Carolina so it starts after its prior subdivision, which begins in 1912-01-01\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. District Court for the District of South Carolina', \n",
    "                  'end_date'] = pd.to_datetime('1911-12-31') # End a day before the legislative start date\n",
    "duplicate = unique_courts[\n",
    "                    unique_courts['court_name'] == \n",
    "                    'U.S. District Court for the District of South Carolina'].copy()\n",
    "duplicate['start_date'] = pd.to_datetime('1965-11-01') # End a day before the legislative end date\n",
    "duplicate['end_date'] = pd.to_datetime('2262-01-01') # End a day before the legislative end date\n",
    "unique_courts = pd.concat([unique_courts, duplicate], ignore_index=True)\n",
    "\n",
    "# Fix end dates for other now-defunct SC courts\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. District Court for the Eastern District of South Carolina', \n",
    "                  'end_date'] = pd.to_datetime('1965-10-31') # End a day before the legislative start date\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. District Court for the Western District of South Carolina', \n",
    "                  'end_date'] = pd.to_datetime('1965-10-31') # End a day before the legislative start date\n",
    "\n",
    "# Create second iteration of Fifth Circuit\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. Court of Appeals for the Fifth Circuit', \n",
    "                  'end_date'] = pd.to_datetime('1981-09-30') # End a day before the legislative start date\n",
    "unique_courts.at[\n",
    "    unique_courts.index[unique_courts['court_name'] == 'U.S. Court of Appeals for the Fifth Circuit'][0], \n",
    "    'states'] = ['Louisiana', 'Texas', 'Mississippi','Alabama','Georgia','Florida']\n",
    "duplicate = unique_courts[\n",
    "                    unique_courts['court_name'] == \n",
    "                    'U.S. Court of Appeals for the Fifth Circuit'].copy()\n",
    "duplicate['start_date'] = pd.to_datetime('1981-10-01') # Start day of legislative start date\n",
    "duplicate['end_date'] = pd.to_datetime('2262-01-01')\n",
    "duplicate['states'] = [['Louisiana', 'Texas', 'Mississippi']]\n",
    "unique_courts = pd.concat([unique_courts, duplicate], ignore_index=True)\n",
    "\n",
    "# Create second iteration of eighth circuit\n",
    "eighth_states = ['Nebraska', 'Minnesota', 'Iowa', 'Arkansas', 'South Dakota', 'Missouri', 'North Dakota']\n",
    "tenth_states = ['Kansas', 'Colorado', 'New Mexico', 'Utah', 'Wyoming', 'Oklahoma']\n",
    "unique_courts.loc[unique_courts['court_name'] == \n",
    "                  'U.S. Court of Appeals for the Eighth Circuit', \n",
    "                  'end_date'] = pd.to_datetime('1929-03-27') # End a day before the legislative start date\n",
    "unique_courts.at[\n",
    "    unique_courts.index[unique_courts['court_name'] == 'U.S. Court of Appeals for the Eighth Circuit'][0], \n",
    "    'states'] = eighth_states + tenth_states\n",
    "duplicate = unique_courts[\n",
    "                    unique_courts['court_name'] == \n",
    "                    'U.S. Court of Appeals for the Eighth Circuit'].copy()\n",
    "duplicate['start_date'] = pd.to_datetime('1929-03-28') # Start day of legislative start date\n",
    "duplicate['end_date'] = pd.to_datetime('2262-01-01')\n",
    "duplicate['states'] = [eighth_states]\n",
    "unique_courts = pd.concat([unique_courts, duplicate], ignore_index=True)\n",
    "\n",
    "# Sort so oldest iteration of each court is first\n",
    "unique_courts = unique_courts.sort_values(['court_type','court_name','start_date'])\n",
    "\n",
    "# Add an ID column\n",
    "unique_courts['id'] = range(1, len(unique_courts) + 1)\n",
    "\n",
    "# Fix the end dates so that they are WAY in the future, max date for pd datetime\n",
    "unique_courts.loc[unique_courts['end_date'] > '1982-01-01', 'end_date'] = pd.to_datetime('2262-01-01')\n",
    "\n",
    "# Reorder columns\n",
    "unique_courts = unique_courts[['id', 'court_type', 'court_name', 'start_date', 'end_date', 'states']]\n",
    "\n",
    "# Extract district_name and state_name for \"U.S. District Court\"\n",
    "# This is all necessary for joining to the geojson files\n",
    "def extract_district_and_state(court_name):\n",
    "    if \"U.S. District Court for the\" in court_name:\n",
    "        parts = court_name.replace(\"U.S. District Court for the \", \"\").split(\" of \")\n",
    "        if len(parts) == 2:\n",
    "            if parts[1] == 'Columbia':\n",
    "                return f\"{parts[0]} of {parts[1]}\", f\"{parts[0]} of {parts[1]}\", [f\"{parts[0]} of {parts[1]}\"]\n",
    "            elif parts[0] == 'District':\n",
    "                return f\"{parts[0]} of {parts[1]}\", f\"{parts[0]} of {parts[1]}\", [parts[1]]\n",
    "            else:\n",
    "                return parts[0], f\"{parts[0]} of {parts[1]}\", [parts[1]]\n",
    "    raise ValueError(f\"Unexpected court name format: {court_name}\")\n",
    "\n",
    "unique_courts['partial_district'] = ''\n",
    "unique_courts['full_district'] = ''\n",
    "mask = unique_courts['court_type'] == 'U.S. District Court'\n",
    "results = unique_courts.loc[mask, 'court_name'].apply(extract_district_and_state)\n",
    "unique_courts.loc[mask, ['partial_district', 'full_district', 'states']] = pd.DataFrame(results.tolist(), index=results.index, columns=['partial_district', 'full_district', 'states'])\n",
    "\n",
    "# Add a boolean called in_box to indicate whether it will be in the inset map\n",
    "unique_courts['in_box'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7044781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "# All spatial data is in SRID 4326\n",
    "# A lot of this is a start to having shapes change as the courts changed,\n",
    "# but little is needed due to a more recent cutoff date.\n",
    "# Among other things, we have to account for each time districts within a state changed\n",
    "# as the creation/deletion would have led to changes in the shape of the state's other districts.\n",
    "# This occurred in several states since 1912, including IL, LA, CA, FL, IN, NC, GA, OK\n",
    "# The circuit shapes also should have changed when AK, PR and HI became states.\n",
    "\n",
    "# If the start date of the court is prior to the end date of the shapefile, add it to geojson.\n",
    "# The court's map start date would be the later of the court's start date or the last start date in the geojson for that court.\n",
    "# The court's map end date would be the earlier of the court's end date or the map's end date.\n",
    "\n",
    "def change_last_end_date(court_id, courts_geojson, new_end_date):\n",
    "    mask = courts_geojson['court_id'] == court_id\n",
    "    if not courts_geojson[mask].empty:\n",
    "        idx = courts_geojson.loc[mask, 'end_date'].idxmax()\n",
    "        courts_geojson.at[idx, 'end_date'] = new_end_date\n",
    "    else:\n",
    "        raise ValueError(f\"No court found with ID {court_id} for new end date.\")\n",
    "\n",
    "cutoff_date = cutoff\n",
    "\n",
    "courts_geojson = gpd.GeoDataFrame(columns=['court_id','court_type','court_name','start_date','end_date',\n",
    "                                           'in_box','map_info','geometry'], geometry='geometry', crs='EPSG:4326')\n",
    "src_folder = r'maps\\simplified'\n",
    "gj_files = sorted([f for f in os.listdir(src_folder) if f.endswith(\".json\")])\n",
    "\n",
    "for file_idx, file in enumerate(gj_files):\n",
    "    gj_filename = os.path.join(src_folder, file)\n",
    "    #print(gj_filename)\n",
    "\n",
    "    map_year = int(file.split('.')[0].split('_')[0])\n",
    "    map_start_date = pd.to_datetime(f'{map_year}-01-01')\n",
    "    map_end_date = pd.to_datetime(f'{map_year+9}-12-31')\n",
    "\n",
    "    if map_end_date < cutoff_date:\n",
    "        #print(f\"Skipping {file} because {map_end_date} is less than cutoff date.\")\n",
    "        continue\n",
    "\n",
    "    gj_file = gpd.read_file(gj_filename)\n",
    "\n",
    "    # Accounting for differences in field names in 2010 file\n",
    "    state_field_key = 'state_terr' if 'state_terr' in gj_file.columns else 'state'\n",
    "    district_field_key = 'judicial_2' if 'judicial_2' in gj_file.columns else 'name'\n",
    "    df_district_key = 'partial_district' if 'judicial_2' in gj_file.columns else 'full_district'\n",
    "\n",
    "    for idx, row in unique_courts.iterrows():\n",
    "        if row['end_date'] < cutoff_date: # South carolina before it was subdivided on the cutoff date\n",
    "            #print(f\"Skipping {row['court_name']} because {row['end_date']} is less than cutoff date.\")\n",
    "            continue\n",
    "        elif row['start_date'] > map_end_date:\n",
    "            #print(f\"Skipping {row['court_name']} because {row['start_date']} is greater than {map_end_date}.\")\n",
    "            continue\n",
    "        elif row['end_date'] < map_start_date:\n",
    "            #print(f\"Skipping {row['court_name']} because {row['end_date']} is lesss than {map_start_date}.\")\n",
    "            continue\n",
    "\n",
    "        if row['court_type'] == 'U.S. Court of Appeals':\n",
    "            states_list = row['states']\n",
    "            match = gj_file[gj_file[state_field_key].isin(states_list)]\n",
    "            geometry = match.dissolve(by=state_field_key,\n",
    "                                    aggfunc={state_field_key: lambda x: list(set(x))}\n",
    "                                    ).union_all(method='unary') if not match.empty else None\n",
    "        else:\n",
    "            match = gj_file[\n",
    "                (gj_file[state_field_key] == row['states'][0]) &\n",
    "                (gj_file[district_field_key] == row[df_district_key])\n",
    "            ]\n",
    "            geometry = match.iloc[0].geometry if not match.empty else None\n",
    "\n",
    "        if match.empty and row['end_date'] < map_end_date: # the court ended during this map period\n",
    "            # so, we need to update the shape that was last added to courts_geojson for this court\n",
    "            # to insert the court's end date and ensure that prior shape will display\n",
    "            change_last_end_date(row['id'], courts_geojson, row['end_date'])\n",
    "        elif match.empty:\n",
    "            #print(f\"No match found for {row['court_name']} with start date of {row['start_date']} in shapefile {file}.\")\n",
    "            continue\n",
    "        \n",
    "        if file_idx == len(gj_files) - 1:\n",
    "            end_date = pd.to_datetime('2262-01-01')\n",
    "        else:\n",
    "            end_date = min(row['end_date'], map_end_date)\n",
    "\n",
    "        # For the first file, we will set the start date to the later of the cutoff date or the court's start date\n",
    "        # if it is the first time this court is being added, we will set the start date to the earlier of the court start date or the map start date\n",
    "        # otherwise, the start date is the map start date\n",
    "        last_start_date = courts_geojson.loc[courts_geojson['court_id'] == row['id'], 'start_date'].max() or None\n",
    "        if file_idx == 0 or (row['court_type'] == 'U.S. Court of Appeals' and pd.isna(last_start_date)):\n",
    "            start_date = max(row['start_date'], cutoff_date)\n",
    "        elif row['start_date'] > map_start_date:\n",
    "            start_date = max(row['start_date'], map_start_date) if pd.isna(last_start_date) else map_start_date\n",
    "        else:\n",
    "            start_date = min(row['start_date'], map_start_date) if pd.isna(last_start_date) else map_start_date\n",
    "\n",
    "        # get some info about the geometry added to the geojson        \n",
    "        map_info = f'{match[state_field_key].tolist()} - {file}'\n",
    "\n",
    "        # Append row to courts_geojson\n",
    "        courts_geojson.loc[len(courts_geojson)] = {\n",
    "            'court_id': row['id'],\n",
    "            'court_type': row['court_type'],\n",
    "            'court_name': row['court_name'],\n",
    "            'start_date': start_date.strftime('%Y-%m-%d'),\n",
    "            'end_date': end_date.strftime('%Y-%m-%d'),\n",
    "            'in_box': row['in_box'],\n",
    "            'map_info': map_info,\n",
    "            'geometry': geometry\n",
    "        }\n",
    "\n",
    "# Now, we go through and fix things for those \n",
    "# that will be displayed or not\n",
    "# Populate those columns correctly\n",
    "# Remove geometry for any courts not being displayed\n",
    "\n",
    "only_in_box = {'U.S. District Court for the District of Alaska': 'AK',\n",
    "               'U.S. District Court for the District of Hawaii': 'HI',\n",
    "               'U.S. District Court for the District of Puerto Rico': 'PR',}\n",
    "also_in_box = {'U.S. Court of Appeals for the District of Columbia Circuit': 'DC',\n",
    "               'U.S. District Court for the District of Columbia': 'DC',\n",
    "               'U.S. District Court for the District of Rhode Island': 'RI'}\n",
    "\n",
    "for idx, row in courts_geojson.iterrows():\n",
    "    if row['court_name'] in only_in_box:\n",
    "        courts_geojson.at[idx, 'in_box'] = True\n",
    "        courts_geojson.at[idx, 'geometry'] = None\n",
    "        courts_geojson.at[idx, 'abbr'] = only_in_box[row['court_name']]\n",
    "    elif row['court_name'] in also_in_box:\n",
    "        courts_geojson.at[idx, 'in_box'] = True\n",
    "        courts_geojson.at[idx, 'abbr'] = also_in_box[row['court_name']]\n",
    "\n",
    "# Need to remove any keys with null values from each feature, to save space.\n",
    "# Convert GeoDataFrame to GeoJSON string\n",
    "geojson_str = courts_geojson.to_json()\n",
    "\n",
    "# Parse it\n",
    "data = json.loads(geojson_str)\n",
    "\n",
    "# Strip out null-valued keys from properties\n",
    "for feature in data['features']:\n",
    "    props = feature['properties']\n",
    "    feature['properties'] = {k: v for k, v in props.items() if v is not None}\n",
    "\n",
    "# Save to file with compact formatting\n",
    "with open('docs\\\\courts.geojson', 'w') as f:\n",
    "    json.dump(data, f, separators=(',', ':'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c326f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Now, create the slimmed down judges data json\n",
    "\n",
    "# Filter to dates on or after cutoff\n",
    "df = result_df[result_df['date'] >= cutoff].copy()\n",
    "\n",
    "# Create the nested dictionary\n",
    "result = defaultdict(dict)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    court = unique_courts[(unique_courts['court_name'] == row['court_name']) &\n",
    "                          (unique_courts['start_date'] <= row['date'])\n",
    "                          ].sort_values('start_date', ascending=False).iloc[0]\n",
    "    court_id = int(court['id'])\n",
    "    date_str = row['date'].strftime('%Y-%m-%d')\n",
    "    rep_act_percentage = row['total_active_rep'] / row['total_active_judges'] if row['total_active_judges'] > 0 else -1\n",
    "    rep_percentage = row['total_rep'] / row['total_judges'] if row['total_judges'] > 0 else -1\n",
    "    result[court_id][date_str] = [row['total_active_judges'],row['total_active_dem'],row['total_active_rep'],rep_act_percentage,\n",
    "                                  row['total_judges'],row['total_dem'],row['total_rep'],rep_percentage]\n",
    "\n",
    "# Convert to regular dict for JSON output\n",
    "#json_output = json.dumps(result, indent=2)\n",
    "json_output = json.dumps(result, separators=(',', ':'))\n",
    "\n",
    "# Save to file\n",
    "with open('docs\\\\judges.json', 'w') as f:\n",
    "    f.write(json_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
